{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plot spatiotemporal clustering results for effect of continuous variable\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Jose C. Garcia Alanis <alanis.jcg@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\nfrom sklearn.linear_model import LinearRegression\n\nfrom mne.stats.cluster_level import _setup_connectivity, _find_clusters, \\\n    _reshape_clusters\nfrom mne.channels import find_ch_connectivity\nfrom mne.datasets import limo\nfrom mne.decoding import Vectorizer, get_coef\nfrom mne.evoked import EvokedArray\nfrom mne.viz import plot_topomap, plot_compare_evokeds, tight_layout\nfrom mne import combine_evoked, find_layout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we'll import multiple subjects from the LIMO-dataset and compute\ngroup-level beta-coefficients for a continuous predictor, in addition we show\nhow confidence (or significance) levels can be computed for this effects\nusing the bootstrap-t technique and spatiotemporal clustering\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# list with subjects ids that should be imported\nsubjects = list(range(1, 19))\n# create a dictionary containing participants data for easy slicing\nlimo_epochs = {str(subj): limo.load_data(subject=subj) for subj in subjects}\n\n# interpolate missing channels\nfor subject in limo_epochs.values():\n    subject.interpolate_bads(reset_bads=True)\n    subject = subject.crop(tmin=0, tmax=0.35)\n    # only keep eeg channels\n    subject.pick_types(eeg=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "regression parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# variables to be used in the analysis (i.e., predictors)\npredictors = ['intercept', 'face a - face b', 'phase-coherence']\n\n# number of predictors\nn_predictors = len(predictors)\n\n# save epochs information (needed for creating a homologous\n# epochs object containing linear regression result)\nepochs_info = limo_epochs[str(subjects[0])].info\n\n# number of channels and number of time points in each epoch\n# we'll use this information later to bring the results of the\n# the linear regression algorithm into an eeg-like format\n# (i.e., channels x times points)\nn_channels = len(epochs_info['ch_names'])\nn_times = len(limo_epochs[str(subjects[0])].times)\n\n# also save times first time-point in data\ntimes = limo_epochs[str(subjects[0])].times\ntmin = limo_epochs[str(subjects[0])].tmin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "create empty objects  for the storage of results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# place holders for bootstrap samples\nbetas = np.zeros((len(limo_epochs.values()),\n                  n_channels * n_times))\n\n# dicts for results evoked-objects\nbetas_evoked = dict()\nt_evokeds = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "run regression analysis for each subject\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# loop through subjects, set up and fit linear model\nfor iteration, subject in enumerate(limo_epochs.values()):\n\n    # --- 1) create design matrix ---\n    # use epochs metadata\n    design = subject.metadata.copy()\n\n    # add intercept (constant) to design matrix\n    design = design.assign(intercept=1)\n\n    # effect code contrast for categorical variable (i.e., condition a vs. b)\n    design['face a - face b'] = np.where(design['face'] == 'A', 1, -1)\n\n    # order columns of design matrix\n    design = design[predictors]\n\n    # column of betas array (i.e., predictor) to run bootstrap on\n    pred_col = predictors.index('phase-coherence')\n\n    # --- 2) vectorize (eeg-channel) data for linear regression analysis ---\n    # data to be analysed\n    data = subject.get_data()\n\n    # vectorize data across channels\n    Y = Vectorizer().fit_transform(data)\n\n    # --- 3) fit linear model with sklearn's LinearRegression ---\n    # we already have an intercept column in the design matrix,\n    # thus we'll call LinearRegression with fit_intercept=False\n    linear_model = LinearRegression(fit_intercept=False)\n    linear_model.fit(design, Y)\n\n    # --- 4) extract the resulting coefficients (i.e., betas) ---\n    # extract betas\n    coefs = get_coef(linear_model, 'coef_')\n    # only keep relevant predictor\n    betas[iteration, :] = coefs[:, pred_col]\n\n    # the matrix of coefficients has a shape of number of observations in\n    # the vertorized channel data by number of predictors;\n    # thus, we can loop through the columns i.e., the predictors)\n    # of the coefficient matrix and extract coefficients for each predictor\n    # in order to project them back to a channels x time points space.\n    lm_betas = dict()\n\n    # extract coefficients\n    beta = betas[iteration, :]\n    # back projection to channels x time points\n    beta = beta.reshape((n_channels, n_times))\n    # create evoked object containing the back projected coefficients\n    lm_betas['phase-coherence'] = EvokedArray(beta, epochs_info, tmin)\n\n    # save results\n    betas_evoked[str(subjects[iteration])] = lm_betas\n\n    # clean up\n    del linear_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "compute mean beta-coefficient for predictor phase-coherence\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# subject ids\nsubjects = [str(subj) for subj in subjects]\n\n# extract phase-coherence betas for each subject\nphase_coherence = [betas_evoked[subj]['phase-coherence'] for subj in subjects]\n\n# average phase-coherence betas\nweights = np.repeat(1 / len(phase_coherence), len(phase_coherence))\nga_phase_coherence = combine_evoked(phase_coherence, weights=weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "compute bootstrap confidence interval for phase-coherence betas and t-values\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# set random state for replication\nrandom_state = 42\nrandom = np.random.RandomState(random_state)\n\n# number of random samples\nboot = 2000\n\n# place holders for bootstrap samples\ncluster_H0 = np.zeros(boot)\nf_H0 = np.zeros(boot)\n\n# setup connectivity\nn_tests = betas.shape[1]\nconnectivity, ch_names = find_ch_connectivity(epochs_info, ch_type='eeg')\nconnectivity = _setup_connectivity(connectivity, n_tests, n_times)\n\n# threshond for clustering\nthreshold = 100.\n\n# run bootstrap for regression coefficients\nfor i in range(boot):\n    # extract random subjects from overall sample\n    resampled_subjects = random.choice(range(betas.shape[0]),\n                                       betas.shape[0],\n                                       replace=True)\n    # resampled betas\n    resampled_betas = betas[resampled_subjects, :]\n\n    # compute standard error of bootstrap sample\n    se = resampled_betas.std(axis=0) / np.sqrt(resampled_betas.shape[0])\n\n    # center re-sampled betas around zero\n    for subj_ind in range(resampled_betas.shape[0]):\n        resampled_betas[subj_ind, :] = resampled_betas[subj_ind, :] - \\\n                                       betas.mean(axis=0)\n\n    # compute t-values for bootstrap sample\n    t_val = resampled_betas.mean(axis=0) / se\n    # transform to f-values\n    f_vals = t_val ** 2\n\n    # transpose for clustering\n    f_vals = f_vals.reshape((n_channels, n_times))\n    f_vals = np.transpose(f_vals, (1, 0))\n    f_vals = f_vals.ravel()\n\n    # compute clustering on squared t-values (i.e., f-values)\n    clusters, cluster_stats = _find_clusters(f_vals,\n                                             threshold=threshold,\n                                             connectivity=connectivity,\n                                             tail=1)\n    # save max cluster mass. Combined, the max cluster mass values from\n    # computed on the basis of the bootstrap samples provide an approximation\n    # of the cluster mass distribution under H0\n    if len(clusters):\n        cluster_H0[i] = cluster_stats.max()\n    else:\n        cluster_H0[i] = np.nan\n\n    # save max f-value\n    f_H0[i] = f_vals.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "estimate t-test based on original phase coherence betas\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# estimate t-values and f-values\nse = betas.std(axis=0) / np.sqrt(betas.shape[0])\nt_vals = betas.mean(axis=0) / se\nf_vals = t_vals ** 2\n\n# transpose for clustering\nf_vals = f_vals.reshape((n_channels, n_times))\nf_vals = np.transpose(f_vals, (1, 0))\nf_vals = f_vals.reshape((n_times * n_channels))\n\n# find clusters\nclusters, cluster_stats = _find_clusters(f_vals,\n                                         threshold=threshold,\n                                         connectivity=connectivity,\n                                         tail=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "compute significance level for clusters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# get upper CI bound from cluster mass H0\nclust_threshold = np.quantile(cluster_H0[~np.isnan(cluster_H0)], [.95])\n\n# good cluster inds\ngood_cluster_inds = np.where(cluster_stats > clust_threshold)[0]\n\n# reshape clusters\nclusters = _reshape_clusters(clusters, (n_times, n_channels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "back projection to channels x time points\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t_vals = t_vals.reshape((n_channels, n_times))\nf_vals = f_vals.reshape((n_times, n_channels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "create evoked object containing the resulting t-values\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "group_t = dict()\ngroup_t['phase-coherence'] = EvokedArray(np.transpose(f_vals, (1, 0)),\n                                         epochs_info,\n                                         tmin)\n# scaled values for plot\ngroup_t['phase-coherence-scaled'] = EvokedArray(np.transpose(f_vals * 1e-6,\n                                                             (1, 0)),\n                                                epochs_info,\n                                                tmin)\n\n# electrodes to plot (reverse order to be compatible whit LIMO paper)\npicks = group_t['phase-coherence'].ch_names[::-1]\n# plot t-values, masking non-significant time points.\nfig = group_t['phase-coherence'].plot_image(time_unit='s',\n                                            picks=picks,\n                                            # mask=sig_mask,\n                                            xlim=(0., None),\n                                            unit=False,\n                                            # keep values scale\n                                            scalings=dict(eeg=1),\n                                            cmap='viridis',\n                                            clim=dict(eeg=[0, None])\n                                            )\nfig.axes[1].set_title('F-value')\nfig.axes[0].set_title('Group-level effect of phase-coherence')\nfig.set_size_inches(6.5, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "visualize clusters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# get sensor positions via layout\npos = find_layout(epochs_info).pos\n\n# loop over clusters\nfor i_clu, clu_idx in enumerate(good_cluster_inds):\n    # unpack cluster information, get unique indices\n    time_inds, space_inds = np.squeeze(clusters[clu_idx])\n    ch_inds = np.unique(space_inds)\n    time_inds = np.unique(time_inds)\n\n    # get topography for F stat\n    f_map = f_vals[time_inds, :].mean(axis=0)\n\n    # get signals at the sensors contributing to the cluster\n    sig_times = times[time_inds]\n\n    # create spatial mask\n    mask = np.zeros((f_map.shape[0], 1), dtype=bool)\n    mask[ch_inds, :] = True\n\n    # initialize figure\n    fig, ax_topo = plt.subplots(1, 1, figsize=(10, 3))\n\n    # plot average test statistic and mark significant sensors\n    image, _ = plot_topomap(f_map, pos, mask=mask, axes=ax_topo, cmap='Reds',\n                            vmin=np.min, vmax=np.max, show=False)\n\n    # create additional axes (for ERF and colorbar)\n    divider = make_axes_locatable(ax_topo)\n\n    # add axes for colorbar\n    ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n    plt.colorbar(image, cax=ax_colorbar)\n    ax_topo.set_xlabel(\n        'Averaged F-map ({:0.3f} - {:0.3f} s)'.format(*sig_times[[0, -1]]))\n\n    # add new axis for time courses and plot time courses\n    ax_signals = divider.append_axes('right', size='300%', pad=1.2)\n    title = 'Cluster #{0}, {1} sensor'.format(i_clu + 1, len(ch_inds))\n    if len(ch_inds) > 1:\n        title += \"s (mean)\"\n\n    plot_compare_evokeds(group_t['phase-coherence-scaled'],\n                         title=title,\n                         picks=ch_inds,\n                         combine='mean',\n                         axes=ax_signals,\n                         show=False,\n                         split_legend=True,\n                         truncate_yaxis='max_ticks')\n\n    # plot temporal cluster extent\n    ymin, ymax = ax_signals.get_ylim()\n    ax_signals.fill_betweenx((ymin, ymax), sig_times[0], sig_times[-1],\n                             color='orange', alpha=0.3)\n    ax_signals.set_ylabel('F-value')\n\n    # clean up viz\n    tight_layout(fig=fig)\n    fig.subplots_adjust(bottom=.05)\n    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}